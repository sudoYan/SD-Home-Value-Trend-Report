{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2418d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d85143c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('stops_files')\n",
    "transit_dfs = {}\n",
    "for file in folder_path.glob(\"*.txt\"):\n",
    "    df = pd.read_csv(file)\n",
    "    transit_dfs[file.name] = df\n",
    "\n",
    "common_cols = set(transit_dfs['1206.txt'].columns)\n",
    "for df in transit_dfs.values():\n",
    "    common_cols = common_cols.intersection(df.columns)\n",
    "    \n",
    "for yymm in transit_dfs:\n",
    "    df = transit_dfs[yymm]\n",
    "    df = df[list(common_cols)]\n",
    "    df = df.drop(['stop_code', 'stop_place', 'reference_place', 'parent_station', 'wheelchair_boarding', 'intersection_code', 'stop_name'], axis=1)\n",
    "    transit_dfs[yymm] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ad5d6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_gdfs = {}\n",
    "for yymm in transit_dfs:\n",
    "    transit_gdfs[yymm] = gpd.GeoDataFrame(transit_dfs[yymm], geometry=gpd.points_from_xy(y=transit_dfs[yymm].stop_lon, x=transit_dfs[yymm].stop_lat), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a45a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/1s145dnx53b_5zr2zxzzh0bc0000gn/T/ipykernel_24944/747986790.py:8: UserWarning: `keep_geom_type=True` in overlay resulted in 960 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  neighborhoods_cleaned = gpd.overlay(neighborhoods, uncounted_zones, how='difference')\n",
      "/Users/aryandixit/Desktop/Group136_SP25/env/lib/python3.13/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "neighborhoods = gpd.read_file(\"SDPD_Beats_shapefile/SDPD_Beats.shp\")\n",
    "neighborhoods['area'] = neighborhoods.geometry.area\n",
    "neighborhoods = neighborhoods[neighborhoods['area'] > 150000]\n",
    "zones = gpd.read_file(\"Zoning_Base_SD_shapefile/Zoning_Base_SD.shp\")\n",
    "uncounted_zones = zones[zones[\"ZONE_NAME\"].isin([\"AR-1-1\", \"AG-1-1\", \"AR-1-2\"])]\n",
    "neighborhoods = neighborhoods.to_crs(epsg=32611)\n",
    "uncounted_zones = uncounted_zones.to_crs(epsg=32611)\n",
    "neighborhoods_cleaned = gpd.overlay(neighborhoods, uncounted_zones, how='difference')\n",
    "zones_c = zones[~zones[\"ZONE_NAME\"].isin([\"AR-1-1\", \"AG-1-1\", \"AR-1-2\"])]\n",
    "zones_c['zone_id'] = zones_c.index.astype(str)\n",
    "zones_c = zones_c.to_crs(epsg=32611)\n",
    "neighborhoods_cleaned = neighborhoods_cleaned.to_crs(epsg=32611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a80d1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zf/1s145dnx53b_5zr2zxzzh0bc0000gn/T/ipykernel_24944/9663140.py:1: UserWarning: `keep_geom_type=True` in overlay resulted in 42 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  zones_with_neighborhoods = gpd.overlay(zones_c, neighborhoods_cleaned[['NAME', 'geometry']], how='intersection')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zones_with_neighborhoods = gpd.overlay(zones_c, neighborhoods_cleaned[['NAME', 'geometry']], how='intersection')\n",
    "zones_with_neighborhoods = zones_with_neighborhoods.rename(columns={'NAME': 'neighborhood'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1b53781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_with_neighborhoods['centroid'] = zones_with_neighborhoods.geometry.centroid\n",
    "zones_centroids = zones_with_neighborhoods.set_geometry('centroid')\n",
    "zones_centroids['buffer_1000m'] = zones_centroids.geometry.buffer(1000)\n",
    "zones_buffers = zones_centroids.set_geometry('buffer_1000m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "157608bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yymm in transit_gdfs:\n",
    "    transit_gdfs[yymm] = transit_gdfs[yymm].to_crs(epsg=32611)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "92a9821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name_short</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>location_type</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>zone_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [stop_name_short, stop_lon, stop_lat, location_type, stop_id, geometry, index_right, zone_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transit_gdf = transit_gdfs['1410.txt']\n",
    "transit_gdf = transit_gdf.to_crs(zones_buffers.crs)\n",
    "stops_within_buffers = gpd.sjoin(transit_gdf, zones_buffers[['zone_id', 'buffer_1000m']], predicate='within', how='inner')\n",
    "stops_within_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f3c459d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid geometries count: 4700\n"
     ]
    }
   ],
   "source": [
    "print(\"Invalid geometries count:\", (~transit_gdf.geometry.is_valid).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b19c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_counts = stops_within_buffers.groupby('zone_id').size().reset_index(name='stop_count')\n",
    "zones_with_counts = zones_with_neighborhoods.merge(stop_counts, on='zone_id', how='left')\n",
    "zones_with_counts['stop_count'] = zones_with_counts['stop_count'].fillna(0).astype(int)\n",
    "\n",
    "zones_with_counts[zones_with_counts['stop_count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e1a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryandixit/Desktop/Group136_SP25/env/lib/python3.13/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m stops_with_buffers = gpd.sjoin(transit_gdf, buffers, predicate=\u001b[33m'\u001b[39m\u001b[33mwithin\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m stops_with_buffers = stops_with_buffers.rename(columns={\u001b[33m'\u001b[39m\u001b[33mzone_id\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mzone_id\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m stop_zone_counts = \u001b[43mstops_with_buffers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstop_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNAME\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.size().reset_index(name=\u001b[33m'\u001b[39m\u001b[33mn_zone_buffers\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m stops_with_weights = stops_with_buffers.merge(stop_zone_counts, on=[\u001b[33m'\u001b[39m\u001b[33mstop_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNAME\u001b[39m\u001b[33m'\u001b[39m], how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m stops_with_weights[\u001b[33m'\u001b[39m\u001b[33mweighted_contribution\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m1\u001b[39m / stops_with_weights[\u001b[33m'\u001b[39m\u001b[33mn_zone_buffers\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Group136_SP25/env/lib/python3.13/site-packages/pandas/core/frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Group136_SP25/env/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Group136_SP25/env/lib/python3.13/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'NAME'"
     ]
    }
   ],
   "source": [
    "#NOT WORKING\n",
    "neighborhoods_cleaned = neighborhoods_cleaned.to_crs(epsg=26911)\n",
    "zones_c = zones_c.to_crs(epsg=26911)\n",
    "\n",
    "zones_c['centroid'] = zones_c.geometry.centroid\n",
    "zones_centroids = zones_c\n",
    "zones_centroids['centroid'] = zones_centroids.geometry.centroid\n",
    "zones_centroids = zones_centroids.set_geometry('centroid')\n",
    "zones_centroids['buffer_850m'] = zones_centroids.geometry.buffer(850)\n",
    "buffers = zones_centroids.set_geometry('buffer_850m')\n",
    "zone_centroids = zones_centroids.set_geometry('centroid')\n",
    "zones_with_nhoods = gpd.sjoin(zone_centroids, neighborhoods_cleaned, predicate='within', how='left')[['zone_id', 'NAME']]\n",
    "zones_c = zones_c.merge(zones_with_nhoods, on='zone_id', how='left')\n",
    "\n",
    "\n",
    "for yymm in transit_gdfs:\n",
    "    transit_gdf = transit_gdfs[yymm]\n",
    "    stops_with_buffers = gpd.sjoin(transit_gdf, buffers, predicate='within', how='left')\n",
    "    stops_with_buffers = stops_with_buffers.rename(columns={'zone_id': 'zone_id'})\n",
    "    \n",
    "    stop_zone_counts = stops_with_buffers.groupby(['stop_id', 'NAME']).size().reset_index(name='n_zone_buffers')\n",
    "    stops_with_weights = stops_with_buffers.merge(stop_zone_counts, on=['stop_id', 'NAME'], how='left')\n",
    "    stops_with_weights['weighted_contribution'] = 1 / stops_with_weights['n_zone_buffers']\n",
    "\n",
    "    zone_scores = stops_with_weights.groupby(['zone_id', 'NAME'])['weighted_contribution'].sum().reset_index()\n",
    "    neighborhood_scores = zone_scores.groupby('NAME')['weighted_contribution'].sum().reset_index(name='neighborhood_score')\n",
    "\n",
    "    neighborhoods_cleaned_l = neighborhoods_cleaned.merge(neighborhood_scores, on='NAME', how='left').fillna({'neighborhood_score': 0})\n",
    "    neighborhoods_cleaned_l.plot(column='neighborhood_score', cmap='plasma', legend=True, figsize=(12,12))\n",
    "    plt.title(\"Transit Stop Score (10 min walk adjusted)\", fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea48258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ZONE_NAME', 'IMP_DATE', 'ORDNUM', 'Shape_Leng', 'Shape_Area',\n",
      "       'geometry', 'zone_id', 'centroid', 'buffer_850m'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(zones_centroids.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zoning and classify\n",
    "zones = gpd.read_file(\"Zoning_Base_SD_shapefile/Zoning_Base_SD.shp\")\n",
    "\n",
    "def classify_zone(z):\n",
    "    if z.startswith(\"RS\") or z.startswith(\"RM\") or z.startswith(\"RX\"):\n",
    "         return \"Residential\"\n",
    "    elif z.startswith(\"CO\") or z.startswith(\"CN\") or z.startswith(\"CC\"):\n",
    "         return \"Commercial\"\n",
    "    elif z.startswith (\"IP\") or z.startswith(\"IL\") or z.startswith(\"IH\"):\n",
    "         return \"Industrial\"\n",
    "    elif z.startswith(\"AG\") or z.startswith(\"AR\"):\n",
    "         return \"Agricultural\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "zones[\"ZONE_NAME\"] = zones[\"ZONE_NAME\"].apply(classify_zone)\n",
    "\n",
    "neighborhoods = gpd.read_file(\"SDPD_Beats_shapefile/SDPD_Beats.shp\")\n",
    "if neighborhoods.crs != zones.crs:\n",
    "    zones = zones.to_crs(neighborhoods.crs)\n",
    "\n",
    "zone_in_neighborhoods = gpd.sjoin(zones,neighborhoods, how=\"inner\", predicate=\"intersects\")\n",
    "zone_counts = zone_in_neighborhoods.groupby([\"NAME\",\"ZONE_NAME\"]).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "for yymm in transit_gdfs:\n",
    "    transit_gdfs[yymm] = transit_gdfs[yymm].to_crs(neighborhoods.crs)\n",
    "\n",
    "    stops_in_neighborhoods = gpd.sjoin(transit_gdfs[yymm], neighborhoods, how=\"inner\", predicate=\"within\")\n",
    "    stop_counts = stops_in_neighborhoods.groupby(\"NAME\").size().reset_index(name=\"stop_count\")\n",
    "\n",
    "    neighborhood_stats = zone_counts.merge(stop_counts, on=\"NAME\", how=\"left\")\n",
    "    neighborhood_stats[\"stop_count\"].fillna(0, inplace=True)\n",
    "\n",
    "    melted = neighborhood_stats.melt(\n",
    "        id_vars=[\"NAME\",\"stop_count\"],\n",
    "        value_vars=[\"Residential\",\"Commercial\",\"Industrial\",\"Agricultural\", \"Other\"],\n",
    "        var_name=\"ZONE_NAME\",\n",
    "        value_name=\"zone_count\"\n",
    "    )\n",
    "\n",
    "    melted[\"stops_per_zone_unit\"] = melted[\"stop_count\"] / (melted[\"zone_count\"] + 1e-6)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.boxplot(data=melted, x=\"ZONE_NAME\", y=\"stops_per_zone_unit\")\n",
    "    plt.title(\"Transit Stop Density by Zone Type in Neighborhoods\")\n",
    "    plt.ylabel(\"Transit Stops per Zone Unit\")\n",
    "    plt.xlabel(\"Zone Type\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
